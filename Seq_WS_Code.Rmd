---
title: "Amplicon Sequencing Workshop with Dr. Henry Birt"
author: "Kaydee S. Barker"
date: '2023-05-02'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install if needed
#BiocManager::install("phyloseq")
#BiocManager::install("DECIPHER")
#BiocManager::install("microbiome")
BiocManager::install("microbiome")

#load libraries
library(rlang)
library(dada2)
library(ShortRead)
library(tidyverse)
library(phangorn)
library(DECIPHER)
library(phyloseq)
library(vegan)
library(microbiome)
library(tidyverse)
library(DescTools)
library(emmeans)
library(multcompView)

```

## Workshop Background

This workshop given by Dr. Henry Birt for the Microbiome Network at the University of Manchester...

## Processing Example Raw 16S Data to Analyze

```{r}

#download.file('https://mothur.s3.us-east-2.amazonaws.com/wiki/miseqsopdata.zip', destfile = "data/miseqsopdata.zip")
#unzip("data/miseqsopdata.zip", exdir = "data/")

path <- "data/MiSeq_SOP/"
files <- list.files("data/MiSeq_SOP/")
#files

num.files <- length(list.files("data/MiSeq_SOP/"))

#trim to four forward and reverse reads
unlink(paste0(path,files[9:num.files]))

#Get full paths for all files and save them for downstream analyses
#Forward and reverse fastq filenames have format: 
fnFs <- sort(list.files(path, pattern="R1_", full.names = TRUE)) #forward read
fnRs <- sort(list.files(path, pattern="R2_", full.names = TRUE)) #reverse read

#Get sample names
sample.names <- sapply(strsplit(basename(fnFs), "R1_"), function(x) x[1])
sample.names <- str_split(string = sample.names, pattern = "_", simplify = T )[,1]

#Create file pathway to place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz")) 
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names


```

### Read quality profiles

#### Inspect the front and reverse read quality profiles

```{r, fig.cap="Heat map of the frequency of each quality score at each base position in forward reads. The mean quality score at each position is shown by the green line,and the quartiles of the quality score distribution by the orange lines. The red line shows the scaled proportion of reads that extend to at least that position."}

#Plot read quality profile
plotQualityProfile(fl = fnFs)

```

```{r, fig.cap="Heat map of the frequency of each quality score at each base position in reverse reads."}

#Plot read quality profile
plotQualityProfile(fl = fnRs)

```

#### Filter and trim, then inspect read quality profiles again

Here we will trim off data with a quality score less than 20.

```{r, fig.cap="Heat map of the frequency of each quality score at each base position in forward reads for the trimmed data."}
#filter and trim
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, #file path of original data, file path of filtered data for each
                     truncLen = c(240,160), #select the first 240 forward reads and 160 reverse reads
                     trimLeft = c(15,15), #trim off the primers for analysis (first 15 reads of each)
                     maxN=0, #remove any sequences that have 'N' which is an error
                     maxEE=c(2,2), #set threshold for expected error scores for forward and reverse
                     truncQ=2, #trim after first instance of truncQ quality score of 2
                     rm.phix=TRUE, compress=TRUE, multithread=FALSE) #on Windows set multithread=FALSE
head(out)

#Plot read quality profile
plotQualityProfile(fl = filtFs)

```

```{r, fig.cap="Heat map of the frequency of each quality score at each base position in reverse reads for the trimmed data."}

#Plot read quality profile
plotQualityProfile(fl = filtRs)

```

#### Identify errors

```{r, fig.cap="Scatterplot and line for expected and actual reads for forward reads. The black line shows the estimated error rates after convergence of the machine-learning algorithm. The red line shows the error rates expected under the nominal definition of the Q-score."}

errF <- learnErrors(filtFs, nbases = 1e8, multithread = TRUE)

plotErrors(errF, nominalQ = TRUE)

```

```{r, fig.cap="Scatterplot and line for expected and actual reads for reverse reads."}

errR <- learnErrors(filtRs, nbases = 1e8, multithread = TRUE)

plotErrors(errR, nominalQ = TRUE)

```

### Sample inference

DADA2 uses a machine learning algorithm to infer unique sequences, or amplicon sequence variants (ASVs) from reads.

```{r}

#apply the core sample inference algorithm to the filtered and trimmed sequence data.
dadaFs <- dada(filtFs, err = errF, multithread = TRUE) #may want to consider pool = TRUE
dadaRs <- dada(filtRs, err = errR, multithread = TRUE)


```

### Merge forward and reverse reads, remove chimeras

```{r}

#Merge 
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, #file path of ASV inference, file path of filtered data for each
                      verbose=TRUE, returnRejects = T)

#Inspect the merger dataframe from the first sample
head(mergers[[1]])

#Create a matrix of ASV counts
seqtab_orig <- makeSequenceTable(mergers)
dim(seqtab_orig)

#Create a table with average read length of ASVs
table(nchar(getSequences(seqtab_orig)))
nchar(colnames(seqtab_orig)) #show number of characters in each column
seqtab <- seqtab_orig[,nchar(colnames(seqtab_orig)) == 225] #keep only columns with 225
dim(seqtab) #look at dimensions of df

#Remove chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim) #look at dimensions of df

```

### Assign taxonomy

```{r}

#Download Silva reference database
#download.file("https://zenodo.org/record/4587955/files/silva_nr99_v138.1_train_set.fa.gz?download=1", destfile = file.path(path, "silva_nr99_v138.1_train_set.fa.gz"), method = "libcurl")

#Implements the RDP Naive Bayesian Classifier algorithm described in Wang et al. Applied and Environmental Microbiology 2007, 
taxa <- assignTaxonomy(seqtab.nochim, "data/MiSeq_SOP/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE) 

table(nchar(getSequences(seqtab.nochim)))

getN <- function(x) sum(getUniques(x)) #create function to get taxa names

track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), 
               sapply(mergers, getN), rowSums(seqtab_orig), 
               rowSums(seqtab), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace
# sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", 
                     "seqtaborig", "seqtab", "nonchim")
rownames(track) <- sample.names

#Look at track
head(track)
colSums(track)
colSums(track)[ncol(track)]/colSums(track)[1]
summary(track[,ncol(track)]) #summary of last column of track 

#View taxa 
taxa.print <- taxa #rmove sequence rownames for display only
rownames(taxa.print) <- paste0("ASV",seq(length(rownames(taxa.print)))) #add ASV number - easier reference in analyses
head(taxa.print)

```

### Write CSV and fasta files

```{r}

dir.create("data/CSVs") #create subfile for data outputs

#Create phyloseq object
env <- data.frame(sample=(1:4), row.names = sample.names)
row.names(seqtab.nochim) <- sample.names
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(env), 
               tax_table(taxa))
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))

#
rownames(taxa.print) <- paste0("ASV", seq(ntaxa(ps)))

write.csv(taxa.print, "data/CSVs/taxa_16s.csv") #write csv

#save an otu table
otu <- as(otu_table(ps), "matrix")
write.csv(otu,"data/CSVs/otu_16s.csv") #write csv

#save a fasta file
dir.create("data/fastas")

#rep-set
rep.set<- colnames(seqtab.nochim)
names(rep.set) <- paste0("ASV",1:length(rep.set))
writeFasta(object = rep.set, file = "data/fastas/rep-set.fasta")

#re-replicate
for(i in seq(nrow(seqtab.nochim))) {
  ids <- paste0("s", i, "_", seq(rowSums(seqtab.nochim)[i]))
  seqs.re_replicated <- rep(colnames(seqtab.nochim), times=seqtab.nochim[i,])
  writeFasta(object = ShortRead(sread = DNAStringSet(seqs.re_replicated),
                                id = BStringSet(ids)),
             file = paste0("data/fastas/final", i,".fasta"), width = 20000)
}

```

## Data Analysis and Visualization

```{r}

#Load example dataset from "microbiome" package
data("atlas1006")
atlas1006
otu.tmp <-  as.matrix(as.data.frame(as.matrix(otu_table(atlas1006))))
env.all <- as(sample_data(atlas1006), "data.frame")
otu.all <- t(otu.tmp)
row.names(env.all) == row.names(otu.all)

#subset for single time point
env <-  env.all[which(env.all$time == 0),]
otu <-  otu.all[which(env.all$time == 0),]

#fill in data for nationality
env$nationality  <- str_replace_na(env$nationality  , replacement = "other") %>%
  as.factor()
summary(env)

#check library sizes
lib.size <- rowSums(otu)
hist(lib.size)
summary(lib.size)

otu.r <- rrarefy(otu,1900)

```

### Alpha Diversity

```{r, fig.cap="Histograms of data distribution for microbiome richness of multiple nationalities."}

#Calculate alpha diversity metrics 
env$sobs <-specnumber(otu.r) #calc richness
env$gini <- apply(otu.r, 1, function(x) Gini(x)) #
env$shannon <- diversity(t(otu.r), index = "shannon") #Shannon Index for Diversity - richness and evenness

#Look at distribution
par(mfrow=c(2, 4)) # Set up the plot layout to display 4 histograms in each of 2 rows

sobs_by_nationality <- split(env$sobs, env$nationality) #split the data by sex - subobjects of an object

for (nationality_level in levels(env$nationality)) {
  hist(sobs_by_nationality[[nationality_level]], 
       main = paste("Histogram for", nationality_level), 
       xlab = "sobs",
       col = "lightblue",
       border = "black")
}

```

```{r, fig.cap="Residuals of microbiome richness and their fit to expected values."}

#Examine residuals
par(mfrow=c(1, 1))
mod <- lm(sobs~nationality,data = env)
plot(mod$residuals)
qqnorm(residuals(mod),
       ylab="Sample Quantiles for residuals")
qqline(residuals(mod),
       col="red")
anova(mod)

```

```{r, fig.cap="Boxplot of microbiome richness by nationality."}

#Boxplot data
ggplot(env, aes(fill=nationality ,x=nationality, y=sobs))+
  geom_boxplot(coef = Inf)+
  geom_jitter(shape=16, position=position_jitter(0.1), size = 0.85)+ #data points
  ylab("Diversity (Observed Species)")+
  xlab("Sampling time")+
  annotate("text", x = 1, y =120, label = "A", fontface =2)+
  annotate("text", x = 2, y =120, label = "B", fontface =2)+
  annotate("text", x = 3, y =120, label = "A", fontface =2)+
  annotate("text", x = 4, y =120, label = "C", fontface =2)+
  annotate("text", x = 5, y =120, label = "AC", fontface =2)+
  annotate("text", x = 6, y =120, label = "C", fontface =2)+
  annotate("text", x = 7, y =120, label = "A", fontface =2)+
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        axis.text.x = element_text(angle = 30, hjust = 1),
        legend.position = 0)

#Posthoc test
mod.pairwise <- as.data.frame(emmeans(mod,pairwise ~nationality, adjust  = "BH")$contrasts)
mod.pairwise.p <- mod.pairwise$p.value 
names(mod.pairwise.p) <- str_replace(mod.pairwise[,1]," - ","-")
mod.pairwise.p.letters <- multcompLetters(mod.pairwise.p)
mod.pairwise.p.letters 


```
### Beta Diversity

```{r, fig.cap="Bray."}

#check beta disper
otu.r.bray <- vegdist(otu.r)
otu.r.euc <- vegdist(sqrt(otu.r), method = "euc")

mod <- betadisper(otu.r.bray, env$nationality, type = "centroid")
permutest(mod, permutations = 999)

mod <- betadisper(otu.r.euc, env$nationality, type = "centroid")
permutest(mod, permutations = 999)


adonis2(otu.r~nationality, method = "bray", data = env)
adonis2(sqrt(otu.r)~nationality, method = "euc", data = env)

# Running NMDS in vegan (metaMDS)
#maximum likelihood
otu.r.bray_NMS <-
  metaMDS(otu.r,
          distance = "bray",
          k = 3,
          maxit = 999, 
          trymax = 30,
          wascores = TRUE)


stressplot(otu.r.bray_NMS)

plot(otu.r.bray_NMS , dis="sites",type="n", xlab = "NMDS1", ylab = "NMDS2")
ordiellipse(otu.r.bray_NMS, env$nationality, kind="sd",lwd=2.5, lty = 1, col="#47a144ff", show.groups = "CentralEurope")
ordiellipse(otu.r.bray_NMS, env$nationality, kind="sd",lwd=2.5, lty = 1, col="#ce1719ff", show.groups = "EasternEurope")
ordiellipse(otu.r.bray_NMS, env$nationality, kind="sd",lwd=2.5, lty = 1, col="#1f78b4", show.groups = "other")
ordiellipse(otu.r.bray_NMS, env$nationality, kind="sd",lwd=2.5, lty = 1, col="#ff7f00", show.groups = "Scandinavia")
ordiellipse(otu.r.bray_NMS, env$nationality, kind="sd",lwd=2.5, lty = 1, col="#6a3d9a", show.groups = "SouthEurope")
ordiellipse(otu.r.bray_NMS, env$nationality, kind="sd",lwd=2.5, lty = 1, col="#ffff99", show.groups = "UKIE")
ordiellipse(otu.r.bray_NMS, env$nationality, kind="sd",lwd=2.5, lty = 1, col="#b15928", show.groups = "US")
points(otu.r.bray_NMS, dis='sites',pch=21,bg=env$nationality, col="#000000", cex=1.5)
legend("topleft",legend=unique(env$nationality),pch=19,col=unique(env$nationality))

#pairwise tests (computationally intense)
#pairwise.adonis(otu.r.bray,factors = env$nationality,p.adjust.m='BH')

```
